{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "# Download NLTK data for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Assuming your dataset file is located at \"\"\n",
        "data_file_path = \"/content/AllCombined.txt\"\n",
        "\n",
        "# Load data from the dataset file\n",
        "with open(data_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "# Convert data to DataFrame\n",
        "df = pd.DataFrame(data, columns=[\"reviewText\"])\n",
        "\n",
        "# Tokenize the reviewText\n",
        "reviewText = df.reviewText.apply(word_tokenize)\n",
        "\n",
        "# Initialize Word2Vec model without building the vocabulary\n",
        "model = Word2Vec(\n",
        "    vector_size=100,\n",
        "    window=10,\n",
        "    min_count=2,\n",
        "    workers=4,\n",
        "    sorted_vocab=False\n",
        ")\n",
        "\n",
        "# Build the vocabulary\n",
        "model.build_vocab(reviewText)\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model.train(reviewText, total_examples=len(reviewText), epochs=10)\n",
        "\n",
        "# Specify the directory to save the model\n",
        "save_dir = \"/content/drive/My Drive/\"\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Save the trained model\n",
        "model_path = os.path.join(save_dir, \"word2vec_model.bin\")\n",
        "model.save(model_path)\n",
        "\n",
        "# Load the saved model\n",
        "model_saved = Word2Vec.load(model_path)\n",
        "\n",
        "# Example of finding similar words\n",
        "similar_words = model_saved.wv.most_similar(\"sports\")\n",
        "print(\"Similar words to 'sports':\", similar_words)\n",
        "\n",
        "# Example of calculating similarity between words\n",
        "similarity_score = model_saved.wv.similarity(w1=\"human\", w2=\"computer\")\n",
        "print(\"Similarity score between 'human' and 'computer':\", similarity_score)\n",
        "\n",
        "similarity_score = model_saved.wv.similarity(w1=\"machine\", w2=\"computer\")\n",
        "print(\"Similarity score between 'machine' and 'computer':\", similarity_score)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mnBgpRaWdBi",
        "outputId": "980714c3-f8a3-4548-f00f-a91c1c16b105"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar words to 'sports': [('sport', 0.778705358505249), ('athletics', 0.7702298760414124), ('volleyball', 0.7701297402381897), ('competitions', 0.7684786915779114), ('cycling', 0.7619398832321167), ('clubs', 0.7479984164237976), ('soccer', 0.7381991744041443), ('stadiums', 0.7299372553825378), ('basketball', 0.7129060626029968), ('cricket', 0.7100526094436646)]\n",
            "Similarity score between 'human' and 'computer': 0.3290643\n",
            "Similarity score between 'machine' and 'computer': 0.71950233\n"
          ]
        }
      ]
    }
  ]
}
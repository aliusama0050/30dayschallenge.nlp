{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Download NLTK resources (only need to run this once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf4_WsWlDJv9",
        "outputId": "93941816-770b-405a-a25c-4d3a4abca6e9"
      },
      "id": "rf4_WsWlDJv9",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/roo_data.csv\")  # Replace with your actual file\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Concatenate text columns\n",
        "data['text'] = data['Interested Type of Books'].astype(str) + ' ' + \\\n",
        "               data['Salary Range Expected'].astype(str) + ' ' + \\\n",
        "               data['In a Realtionship?'].astype(str) + ' ' + \\\n",
        "               data['Gentle or Tuff behaviour?'].astype(str) + ' ' + \\\n",
        "               data['Management or Technical'].astype(str)\n",
        "\n",
        "# Define preprocessing functions\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "data['text'] = data['text'].apply(preprocess_text)\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['Suggested Job Role'] = label_encoder.fit_transform(data['Suggested Job Role'])\n",
        "job_role_labels = label_encoder.classes_\n",
        "\n",
        "# Prepare features and labels\n",
        "X = data['text'].values\n",
        "y = data['Suggested Job Role'].values\n",
        "y= to_categorical(y)\n",
        "# Tokenize text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_sequences = tokenizer.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_sequences, padding='post')\n",
        "\n",
        "# Save tokenizer and label encoder\n",
        "joblib.dump(tokenizer, 'tokenizer.joblib')\n",
        "joblib.dump(label_encoder, 'label_encoder.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDZVlOH9DLLE",
        "outputId": "84931b81-15e1-4ff6-f63d-39e33e6d78c8"
      },
      "id": "lDZVlOH9DLLE",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cO14xf6FxDy",
        "outputId": "8d56816d-8339-494a-b534-ca862bc849d1"
      },
      "id": "7cO14xf6FxDy",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxgm0zWuGH_5",
        "outputId": "b07b3221-a485-4a7c-9d3f-6e205483029a"
      },
      "id": "Dxgm0zWuGH_5",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from google.colab import files\n",
        "\n",
        "# Define model parameters\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 100\n",
        "max_length = X_padded.shape[1]\n",
        "rnn_units = 64\n",
        "num_classes = 34\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "    SimpleRNN(rnn_units, return_sequences=False),\n",
        "    Dense(y.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and capture the training history\n",
        "history = model.fit(X_padded, y, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dJq1pzZNDqSK",
        "outputId": "703c0572-e661-4ae7-b72e-02fee8717d5e"
      },
      "id": "dJq1pzZNDqSK",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0480 - loss: 3.5278 - val_accuracy: 0.0610 - val_loss: 3.5187\n",
            "Epoch 2/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0537 - loss: 3.5133 - val_accuracy: 0.0585 - val_loss: 3.5184\n",
            "Epoch 3/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0583 - loss: 3.5072 - val_accuracy: 0.0595 - val_loss: 3.5221\n",
            "Epoch 4/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0538 - loss: 3.5069 - val_accuracy: 0.0553 - val_loss: 3.5252\n",
            "Epoch 5/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0565 - loss: 3.5035 - val_accuracy: 0.0587 - val_loss: 3.5231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "# Save the label encoder\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "# Save the padded sequences\n",
        "with open('X_padded.pkl', 'wb') as f:\n",
        "    pickle.dump(X_padded, f)\n",
        "\n",
        "# Save the training history\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "YY-HstY4HL-n"
      },
      "id": "YY-HstY4HL-n",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def predict_job_role(text_input, tokenizer, label_encoder, model, max_length):\n",
        "\n",
        "    # Tokenize and pad the input text\n",
        "    sequences = tokenizer.texts_to_sequences([text_input])\n",
        "    padded_sequence = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "    # Predict the job role\n",
        "    prediction = model.predict(padded_sequence)\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "\n",
        "    # Convert the predicted class index to the actual job role label\n",
        "    predicted_job_role = label_encoder.inverse_transform(predicted_class)\n",
        "\n",
        "    return predicted_job_role[0]\n",
        "\n",
        "# Example usage:\n",
        "# text_input = \"Your text input here\"\n",
        "# predicted_job_role = predict_job_role(text_input, tokenizer, label_encoder, model, max_length)\n",
        "# print(f\"Predicted Job Role: {predicted_job_role}\")\n"
      ],
      "metadata": {
        "id": "CX_-79b_Gnd2"
      },
      "id": "CX_-79b_Gnd2",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"I have strong skills in programming, software engineering, and data analysis.\"\n",
        "predicted_job_role = predict_job_role(text_input, tokenizer, label_encoder, model, max_length)\n",
        "print(f\"Predicted Job Role: {predicted_job_role}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSJzkG-ZH4od",
        "outputId": "dff9dc88-7826-4c30-a9b1-d3c042171991"
      },
      "id": "qSJzkG-ZH4od",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\n",
            "Predicted Job Role: Network Security Administrator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVRbnPBSH7Dk"
      },
      "id": "yVRbnPBSH7Dk",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
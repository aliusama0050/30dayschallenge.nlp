{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya4mTYWxAymh",
        "outputId": "539db29f-ae70-4c8a-94bd-e9d9c0e32233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding for 'word': [-8.65685225e-01 -6.84367299e-01  6.19370818e-01 -4.33559567e-01\n",
            " -1.95600593e+00 -9.42253053e-01  1.98815393e+00  1.77353024e+00\n",
            " -3.04565787e+00  2.48411740e-03  3.33412838e+00  1.19950764e-01\n",
            "  3.63943756e-01 -4.26815636e-02 -1.36325121e+00 -6.36989193e-04\n",
            " -1.23032665e+00 -1.64727852e-01  2.05969989e-01 -4.19022989e+00\n",
            "  1.69446886e-01  3.11505914e-01  3.70167375e+00 -4.22700071e+00\n",
            " -8.78831089e-01  1.05965328e+00 -1.19623184e+00  2.74962044e+00\n",
            "  5.32172024e-01  1.07560742e+00  1.40227780e-01  2.08091331e+00\n",
            "  1.29386950e+00 -2.31625214e-01  5.91280520e-01  2.32590914e-01\n",
            "  5.55896997e-01  4.15607870e-01 -2.63778067e+00  2.32064295e+00\n",
            "  5.27472973e-01 -1.15956736e+00 -1.75799954e+00  8.96663368e-01\n",
            " -2.23700666e+00 -2.48903465e+00  2.35863030e-01  8.58638227e-01\n",
            "  8.14582944e-01  1.23008001e+00 -1.00771964e+00  5.11812747e-01\n",
            "  7.85557449e-01  2.61032557e+00 -2.04402709e+00  2.69860446e-01\n",
            "  4.53492463e-01 -1.48393881e+00 -1.86223590e+00  2.41781735e+00\n",
            "  2.17351899e-01 -3.34008098e-01  1.20170057e+00 -1.62833005e-01\n",
            " -6.89794421e-01  4.06800413e+00  3.69912839e+00 -5.06277643e-02\n",
            "  7.75839761e-02 -6.86682403e-01 -9.97729540e-01  6.08290315e-01\n",
            "  3.89394350e-02  5.71233869e-01  1.08607781e+00  7.47605979e-01\n",
            " -9.46469307e-01  9.16014969e-01 -2.53968477e+00  2.07090020e+00\n",
            " -1.21372926e+00  1.47290730e+00  1.09514666e+00  3.98187733e+00\n",
            " -1.61894405e+00  2.28671360e+00 -2.08690956e-01  3.07249522e+00\n",
            "  8.26932549e-01 -1.77801204e+00  8.98906350e-01  2.80867904e-01\n",
            " -1.96599209e+00 -1.48546445e+00 -1.07380497e+00  2.42951021e-01\n",
            "  8.68702710e-01 -2.50191092e+00  6.67426646e-01 -1.01576471e+00]\n",
            "Words similar to 'machine': [('device', 0.9125024080276489), ('computer', 0.8451075553894043), ('camera', 0.8366141319274902), ('file', 0.816057026386261), ('user', 0.8145134449005127), ('software', 0.809266984462738), ('program', 0.807493269443512), ('disk', 0.7971609830856323), ('tool', 0.7968115210533142), ('phone', 0.786141574382782)]\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Read dataset from a text file\n",
        "def read_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = file.readlines()\n",
        "    return [sentence.strip() for sentence in data]\n",
        "\n",
        "# Example dataset file path\n",
        "dataset_file = \"/content/AllCombined.txt\"\n",
        "\n",
        "# Read dataset\n",
        "corpus = read_dataset(dataset_file)\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Example usage\n",
        "# Get embedding for a word\n",
        "print(\"Embedding for 'word':\", model.wv['word'])\n",
        "\n",
        "# Find similar words\n",
        "print(\"Words similar to 'machine':\", model.wv.most_similar('machine'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mnBgpRaWdBi",
        "outputId": "3467dd02-6e64-4ed1-af01-24f42331dd58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new sentences: ['positive' 'positive' 'positive' 'positive']\n"
          ]
        }
      ]
    }
  ]
}